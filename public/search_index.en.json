[{"url":"http://127.0.0.1:1111/","title":"About Me","body":"Shao Stassen\nSenior at Cornell University studying Computer Science with a focus in Robotics\nHere on campus I am doing foundation model and diffusion policy research on the assistive robotic lab EmPRISE. I am also an Autonomous member of the Combat Robotics at Cornell Project Team. I will be updating my site through the semester to reflect my progress in Fast Robots - ECE4160."},{"url":"http://127.0.0.1:1111/Fast Robots Stuff/","title":"ECE 4160 Fast Robots Labs","body":""},{"url":"http://127.0.0.1:1111/Fast Robots Stuff/lab-3/","title":"Lab 3: Time of Flight Sensors","body":"Overview\nIn Lab 3, the objective was to test out the functionalities and capabilities of two VL53L1X Time-of-Flight (ToF) sensors while still having the IMU. The faster and more reliably the robot can sample these distances, the faster it can safely drive. This lab involved permanently wiring the sensors, powering the Artemis from a battery, bypassing I2C address conflicts, and streaming accurate and reliable ToF data over Bluetooth alongside the IMU.\nSensor Placement Strategy\nI plan to mount one ToF sensor on the front center of the car to detect obstacles directly in the driving path, and the other on the side of the car between the wheels. This configuration will allow the robot to avoid forward collisions while simultaneously maintaining a set distance from the sides for tasks, based on what I know from future labs.\nBlind spots: Because the sensors have a relatively narrow Field of View, the robot will likely miss obstacles that are lower than the sensor's mounting height, highly reflective/angled surfaces that bounce the IR light away, or thin obstacles that fall between the front and side sensor's cone of vision. These blind spots will need to be taken into great consideration in the future when I am doing localization.\nI2C Address Conflict\nUsing the Example05_Wire_I2C.ino sketch, I scanned the bus and successfully found the default ToF at address 0x29, and the IMU at address 0x69 on port 0x10000E9C. I determined those numbers specifically by doing isolation tests on the sensors.\nI2C Device Scanning with only the Time of Flight plugged in\nI2C Device Scanning with both the Time of Flight and IMU plugged in\nBoth VL53L1X sensors share the same hardwired default I2C address (0x29). This was a bit unexpected, because its datasheet said that the default address is 0x52. After further investigation, I realized that the address is left-shifted by 1 bit, since the LSB is used for read/write. Since I2C requires unique addresses for each device on the bus, I cannot simply plug both into the Qwiic connector and work with both of them simultaneously.\nTo solve this, I used the XSHUT (shutdown) pin. By wiring the XSHUT pin of ToF sensor 2 to an output pin on the Artemis (Pin A0), I can hold Sensor 2 in hardware shutdown during boot. I then initialize Sensor 1, use software to change its address to 0x30, and finally pull XSHUT high to wake up Sensor 2 at the default 0x29 address. The following is the code that implements what I described above.\nHardware Setup\nI prepared the Artemis by soldering the provided 650mAh RC car battery to a JST jumper cable. I was careful to cut and strip the wires one at a time to avoid shorting the battery. After soldering, I used heat shrink tubing to insulate the exposed wire. I verified the polarity (positive to positive) before plugging it into the Artemis.\nSoldered Battery\nI then successfully tested this by running my BLE Python script and sending some test messages back and forth without the USB-C cable connected.\nPython server on messaging tests on battery\nArtemis on messaging tests on battery\nFinally, I cut one end off of 2 Qwiic cables and soldered one to each of the ToF sensors, noting the color coding (Blue = SDA, Yellow = SCL, Red = 3.3V, Black = GND). And I connected them to the Qwiic connector hub, as shown below in the circuit diagram.\nCircuit Diagram\nSensor Modes, Dual Sensor Integration &amp; Testing\nThe VL53L1X technically supports three distance modes:\nShort: Max distance ~1.3m. Better ambient light immunity.\nMedium: Max distance ~3m.\nLong: Max distance ~4m. Default mode, but highly sensitive to ambient light and lower accuracy at close range.\nThe Medium Mode: I decided to ignore the medium mode for this lab, since it is supported only through the Pololu VL53L1X Library, which would require me to change a lot of the code for the ToF. If I find that I may need something in between short and long mode in the future, I will consider looking at this more carefully.\nBelow is the initial test I did after hooking up both of the ToF sensors and having them both function simultaneously. Note this satisfies Task 8, so I jumped ahead. Refer to the code snippet in the I2C Address section for how I got both of them to work.\nTwo ToF test\nSerial Monitor - Two ToF test\nToF Sensor Speed and Non-Blocking Code\nIn future labs, the robot cannot hang while waiting for a laser to bounce back. To ensure the code executes as fast as possible, I wrote a non-blocking loop that continuously printed the Artemis millis() clock, and only printed ToF data when checkForDataReady() was true.\nLoop Execution Speed: The millis() timestamps incremented every 3 to 4 ms, indicating that the main loop executes at roughly 250 to 330 Hz.\nSampling Rate: Sensor 1 (~46.5 Hz): Looking at some sample data, averaging those gives roughly 21.5 ms per sample, which means Sensor 1 is operating at an average rate of 46.5 Hz. Sensor 2 (~11 Hz): Sensor 2 only gets data once while Sensor 1 gets data 4 times; it is visually obvious it is running much slower.\nSpeed test 1\nSpeed test 2\nSensor Discrepancies: During testing, Sensor 1 sampled significantly faster than Sensor 2. This is because I set Sensor 1 to short mode and Sensor 2 to long mode. Because long mode can reach further, its waves also take longer to travel back.\nData Collection over Bluetooth\nFirst, I wanted to compare the performance difference between the long mode and short mode for the ToF by starting from a white wall, and then slowly dragging my ToF sensors back from the wall for 30+ seconds.\nHere are the results I got: (Note: I collected 2 trials of each for consistency comparison).\nTOF short mode test 1\nTOF short mode test 2\nTOF long mode test 1\nTOF long mode test 2\nMetric Evaluation:\nRange:\nShort Mode: The graphs show a perfectly linear tracking line that abruptly drops to 0 mm just past 2100 mm (~2.1 meters). This defines the absolute maximum physical range in short mode before the sensor's confidence threshold fails. This is higher than expected from the short mode.\nLong Mode: The sensors track linearly up to approximately 4800 mm (~4.8 meters). Beyond this point, the signal breaks down into massive noise spikes (erratically jumping between 0 and 5000 mm). And the noise becomes really bad starting at ~4.2 meters. But this is again higher than expected for long mode.\nAccuracy: Across all four graphs, Sensor 1 (blue) and Sensor 2 (red) overlap almost perfectly during the valid range window. The steady, linear slope as the distance increases demonstrates that the sensors scale proportionally and accurately with real-world distance, with minimal deviation between the two physical units.\nRepeatability: The sensor performance is incredibly consistent. Comparing Short 1 to Short 2, both trials hit their failure point at the exact same ~2100 mm mark. Similarly, Long 1 and Long 2 both experience total signal breakdown at the identical ~4800 mm threshold. The noise profiles and slopes are virtually indistinguishable between trials.\nRanging Time: There is a direct trade-off between range and speed. Short mode allows for a much tighter timing budget (20ms), yielding a fast ranging time of approximately ~45 Hz. To achieve the 4+ meter range in Long mode, the sensors require a larger timing budget (50ms) to leave the optical shutter open longer, reducing the ranging speed to roughly ~20 Hz.\nFrom this experiment, I decided to test the accuracy further by measuring a set distance. I made a setup with a measuring tape, using the provided white board as an object to detect and my box to hold the sensor in one position, with the tape measure recording the right distance, imaged below:\nSetup\nToF Accuracy Analysis (Static Distance Tests)\nI collected static data at four precise distances: 100mm, 200mm, 500mm, and 1000mm. I used a reflective whiteboard as the target. I performed these tests in both Long Mode and Short Mode to compare their performance.\n100mm and 200mm Testing\n100 mm - Short Mode\n100 mm - Long Mode\n200 mm - Short Mode\n200 mm - Long Mode\n500mm and 1000mm Testing\n500 mm - Short Mode\n500 mm - Long Mode\n1000 mm - Short Mode\n1000 mm - Long Mode\nAnalyzing these graphs reveals a disparity between Short and Long mode, which is heavily exacerbated by the reflective whiteboard target:\nShort Mode is Highly Accurate: Across all four distances (100mm, 200mm, 500mm, and 1000mm), Short mode performed really well. The data lines are flat, stable, and cluster very tightly around the true distance. For instance, at 1000mm, both sensors tracked cleanly between 980mm and 1000mm. At 500mm, they were nearly perfectly aligned with the 500mm mark.\nLong Mode: In stark contrast, Long mode failed at close ranges. At 100mm, the Long mode data is pretty noisy, oscillating randomly between 50mm and 200mm. Even at 1000mm, Long mode under-reads the actual distance by nearly 100mm and exhibits high-frequency jitter.\nNow, this is a bit unfair for long mode because it is designed to look for faint signals from up to 4 meters away, so it increases its sensitivity and leaves its optical \"shutter\" open longer. Pointing this highly sensitive mode at a glossy, highly reflective whiteboard at a close distance of 100mm effectively \"blinds\" the sensor.\nSensor Offset: I also observed a slight, consistent offset between Sensor 1 and Sensor 2. Because the physical test setup was identical, this minor variance is likely due to the placement of my ToFs at slightly different angles, causing them to hit the whiteboard at very slightly different angles.\nConclusion: These tests definitively prove that for a small room with a lot of reflection, Short Mode wins because of its accuracy and speed. Long mode's sensitivity to reflection makes it untrustworthy at sub-1-meter distances in this specific environment. However, if future labs require greater than 2 meter distance detection, I would need to use Long mode or implement Medium mode.\nIMU and ToF\nI created a new Bluetooth command (START_BOTH) that simultaneously collects data from the ToF sensors and the IMU (using the Complementary Filter developed in Lab 2).\nBecause the IMU calculates data much faster than the ToF sensors, the IMU updates its angles in the background continuously. Whenever the ToF sensors finish a distance reading, the Artemis grabs the most recent IMU pitch and roll and saves all five variables into parallel arrays.\nDistance and IMU Complementary Pitch and Roll vs. Time for over 10 seconds\nAs seen in the graph above, all three sensors (2 ToFs and 1 IMU) are successfully running in parallel without blocking each other.\nCollaboration\nI collaborated extensively on this project with Ananya Jajodia.\nI referenced Lucca Correia's site for the I2C address and ToF speed test, and Aidan Derocher's site for the wiring diagram and ToF testing.\nChatGPT was used for plotting CSV data and sending ToF data over Bluetooth."},{"url":"http://127.0.0.1:1111/Fast Robots Stuff/lab-2/","title":"Lab 2: IMU","body":"Overview\nIn Lab 2, I integrated a 9DOF IMU with the SparkFun RedBoard Artemis Nano, computed orientation estimates from accelerometer and gyroscope data, analyzed accelerometer noise in the frequency domain, implemented a low-pass filter (LPF), and fused accelerometer + gyroscope estimates with a complementary filter. Finally, I powered the RC car from a battery and recorded driving “stunts” to establish a baseline for future autonomous behavior.\nIMU Setup\nHardware connections\nI connected the SparkFun ICM-20948 IMU breakout to the Artemis using the QWIIC connectors (I2C). The image below shows this setup. I also added a visual indicator by blinking the Artemis LED 3 times on boot; there is an image for this as well.\nArtemis + IMU wiring via QWIIC\nArtemis with blue LED indicator\nExample code works\nI verified basic IMU functionality using the SparkFun library example:\nLibrary: SparkFun 9DoF IMU Breakout - ICM 20948 - Arduino Library\nExample: Example1_Basics\nI modified the code in the example slightly in order to get the serial prints and plotter to work nicely. However, this didn't impact the actual values, so there was minimal effect.\nI confirmed that acceleration (mg) and gyroscope (DPS) values updated as expected while rotating and translating the board.\nExample Code IMU Test\nAD0_VAL (what it is + what it should be)\nAD0_VAL represents the least significant address-selection bit for the IMU’s I2C address (effectively selecting between the two possible I2C addresses depending on the AD0/ADR pin state). In practice:\nIf the IMU ADR/AD0 line is left at its default, AD0_VAL should match that default.\nIf the ADR jumper is bridged/closed, AD0_VAL must be changed accordingly.\nIn my setup, AD0_VAL = 1 because I am just using the default configuration.\nInitial sensor behavior (what changes and why)\nFrom the example output and the calculated roll, pitch, and yaw values for both the accelerometer and gyroscope (shown in later videos):\nAccelerometer: Changes with linear acceleration and also reflects gravity. When the board is still but tilted, the acceleration vector changes because gravity is distributed differently across axes. I also noticed that the accelerometer's data is very noisy. This is expected, since accelerometers are highly sensitive to small vibrations, mechanical disturbances, and electrical noise.\nGyroscope: Changes with angular velocity. When I rotate about an axis, I see a spike primarily on the corresponding gyro axis; when stationary, gyro values return to near zero. For the above example, you can see my gyroscope values stay mostly near zero because my motion is relatively slow, resulting in a small angular velocity being measured.\nAnother important thing is that the parameters change based on the axis being rotated about. For example, when you rotate about the x-axis, you see that the pitch changes the most compared to the other two axes.\nAccelerometer\nPitch and roll from acceleration\nUsing the equations from the lecture, I converted raw accelerometer readings into pitch and roll (degrees). I used atan2() for robust quadrant handling.\nThe video below showcases how I obtained 0, -90, and 90 degrees for the pitch and roll from the accelerometer.\nRoll and Pitch IMU Test\nSpecifically, the 5 images below are static images of me hitting those specific angles.\nAs the images indicate, the accuracy of the accelerometer is pretty decent, as the values are close to their true values, but they are not super precise. I used a 2-point calibration to attempt to make it a bit better. Specifically for pitch, true 0 degrees is about 2 degrees, and true -90 degrees is about -88 degrees. This is easy to fix; you just need to add a 2-degree offset. The roll value is a bit more complicated because true 0 degrees is roughly -1.5, true -90 degrees is about -91, and true 90 degrees is about 92 degrees. Using the slope function, we get the following, where a is the slope and b is the offset:\nAccuracy of the accelerometer\n0 degree - both\npitch 90 degree\npitch -90 degree\nroll 90 degree\nroll -90 degree\n0 degree - pitch\n0 degree - roll\npitch 90 degree\npitch -90 degree\nroll 90 degree\nroll -90 degree\nThe calibrated results end up looking pretty good for pitch and roll at the different critical values.\nData from Accelerometer\nI made a new command in the Artemis code to collect the IMU sensor data with a certain number of samples (in this case, 2048 samples) and transmit them to the Python server. Once the data arrives as a string, I parse them into separate arrays by the type of data (i.e., pitch_a, roll_a, etc.). I then used them to plot graphs for analysis and results.\nThen I used a similar notification handler as in Lab 1 for reading the data.\nHere is the example plotting code I used to generate the different graphs.\nRaw pitch and roll vs. time with RC car in proximity\nThe plots above show raw accelerometer-derived pitch and roll over about 6 seconds. Both signals stay near 0° but exhibit high-frequency oscillations—roughly ±1° for both pitch and roll, indicating sensor noise and vibration from the proximity of the RC car. This raw data is what drives the use of a low-pass filter to reduce noise, which I will analyze in the next section.\nFFT and Low-Pass Filter\nI performed an FFT analysis to characterize accelerometer noise and chose a cutoff frequency for the low-pass filter.\nUsing the Frequency Spectrum to Choose a Cutoff Frequency\nTo determine an appropriate cutoff frequency for the low-pass filter, I analyzed the accelerometer-derived pitch and roll signals in the frequency domain using the Fast Fourier Transform (FFT). Before computing the FFT, I subtracted the mean of each signal to remove the dominant DC component caused by gravity, allowing the vibration and noise content to be more clearly observed.\nThe resulting frequency spectra show that the majority of the signal energy is concentrated at very low frequencies, corresponding to slow changes in orientation. Beyond this region, the spectrum becomes relatively flat and noisy, indicating high-frequency vibrations rather than meaningful motion. When the RC car was running nearby, noticeable energy appeared primarily below approximately 0 - 8 Hz, with no strong, structured peaks at higher frequencies.\nBased on this observation, I decided to pick an end value where most of that noise lies, resulting in a cutoff frequency near 8 Hz for the low-pass filter. This cutoff preserves the low-frequency components associated with real robot motion while attenuating higher-frequency noise. Choosing a cutoff that is too low would over-smooth the signal and suppress legitimate motion (such as a quick tilt or turn), while choosing a cutoff that is too high would allow excessive vibration noise to remain in the signal.\nLow-Pass Filter Design and Effect on the Data\nTo implement the low-pass filter, I used a 4th-order Butterworth filter, which provides a smooth passband and strong attenuation beyond the cutoff frequency. The filter was designed using the inferred sampling frequency of the IMU data and applied using a zero-phase filtfilt operation to avoid phase distortion.\nIn the time domain, the effect of the low-pass filter is clearly visible. The raw pitch and roll signals exhibit rapid, high-frequency oscillations on the order of ±1°, even when the sensor remains near a constant orientation. After filtering, these oscillations are significantly reduced, while the overall trend of the signal is preserved. This confirms that the removed components primarily correspond to noise rather than meaningful motion.\nThe FFT of the filtered signal further validates this choice: frequency components above the cutoff frequency are strongly attenuated, while low-frequency content remains largely unchanged. Together, the frequency-domain and time-domain results demonstrate that the selected cutoff frequency effectively balances noise reduction and signal fidelity.\nRelation to Filter Parameters in Code\nThe cutoff frequency directly determines the filter coefficients used in the Butterworth design. As explained in lecture, the cutoff frequency $f_c$ is related to the time constant $RC$ by\n$$f_c = \\frac{1}{2\\pi RC}$$\nand the smoothing factor $\\alpha$ is related to the sampling period $T$ by\n$$\\alpha = \\frac{T}{T + RC}$$\nTo solve for this theoretical value, I used this code:\nI got an alpha of 0.129 using the cutoff frequency of 8 Hz.\nIn practice, rather than explicitly computing $\\alpha$, I implemented the low-pass filter using a digital Butterworth filter, which internally accounts for the sampling frequency and cutoff frequency. This approach provides a more consistent frequency response and better attenuation characteristics than a simple first-order filter.\nBelow are the frequency-domain plots and raw vs. LPF comparisons.\nFFT of accelerometer data — car in proximity\nRaw vs. low-pass filtered accelerometer data\nFFT: Raw vs. LPF\nAdditional vibration and FFT analysis:\nTo deliberately induce vibrational noise, I placed the IMU on the lab table and gently tapped the table with my hand. As you might notice, the peaks in the following graphs are vibration noise from those impacts—the accelerometer picks up the mechanical shock as high-frequency spikes in pitch and roll. These spikes are generated just by my finger taps. This setup helps characterize how impulsive disturbances affect the raw signal and how well the low-pass filter attenuates them. You can see that the raw signal contains a lot of vibration noise, but the low-pass filter is able to smooth them out.\nVibration Pitch and Roll — table taps\nVibration FFT raw vs. low-pass filtered — table-tap vibration noise\nRaw vs. low-pass filtered — table-tap vibration noise\nGyroscope\nPitch, roll, and yaw from gyroscope\nI integrated angular velocity (DPS) over time to obtain pitch, roll, and yaw angles from the gyroscope:\nGyroscope vs. accelerometer\nThe gyroscope and accelerometer use different axis conventions on the ICM-20948, as we learned in lecture. The gyro pitch/roll axes correspond to the accel roll/pitch axes (with a sign flip for pitch). So I had to correct this mapping in the code with the following edit:\nGyroscope vs Accelerometer in orientation\nFor the most part, the gyroscope tracks quick rotations smoothly but drifts over time due to integration error. The accelerometer is more accurate at low frequencies but is noisy. A complementary filter combines both to get a stable and accurate orientation.\nCurrently, I am at the highest sampling frequency with no delay. I tried putting sleep in the sample data call, which would decrease the sampling frequency. In general, the estimated angles showed increased lag and reduced responsiveness to quick motions. This makes sense because at larger time steps, you miss rapid changes, causing high-frequency vibrations to appear as low-frequency drift.\nComplementary Filter\nI fused the low-pass filtered accelerometer angles with the integrated gyroscope angles using a complementary filter:\nUsing an alpha of 0.05 for both the LPF and the complementary filter (which weights the gyroscope for short-term stability and the accelerometer for long-term accuracy), I got something like this:\nComplementary filter: gyro vs. LPF accelerometer vs. fused\nHowever, you might notice that the graph of the complementary filter is smooth but not very accurate, or it doesn't respond well to changes compared to the LPF's graph. This means I needed to increase the contribution of the accelerometer's LPF to get a smooth and drift-corrected roll and pitch.\nBest Complementary filter: gyro vs. LPF accelerometer vs. fused\nNow this looks better!\nWorking range and accuracy\nWorking range: The complementary filter performs well across the typical operating range of pitch and roll—roughly ±90°. Beyond that, for these positions, the accelerometer-based angles become ill-defined (e.g., when the board is nearly vertical, the atan2 formulation approaches singularities), and the gyroscope integration accumulates more drift. This was knowledge from the microcontroller class.\nAccuracy: With alphaComp = 0.05 and alphaLPF = 0.10, the fused output tracks the LPF accelerometer really well while staying smoother than the raw accel. The filter accuracy is ultimately limited by the accelerometer (calibration, noise) at low frequencies and by the gyroscope (bias, integration error) at high frequencies. Based on my graph, however, it seems to have very good accuracy.\nSampling Data\nSpeed up\nI optimized the main loop to sample the IMU as fast as possible:\nNon-blocking data collection: Instead of blocking on myICM.dataReady() inside the command handler, I check dataReady() in the main loop and call collectIMU() only when new data is available. Data is stored in arrays and sent over Bluetooth in a separate command.\nRemoved debug prints in the IMU read path to reduce overhead.\nStart/stop flags so recording only runs when requested via Bluetooth commands.\nThe main loop runs much faster than the IMU produces data, so the IMU is the bottleneck. Comparing loop_count (main loop count) to imu_samples (samples collected) shows the loop cycles many times per IMU sample.\nNotice I decided to only send time, raw pitch and roll from the accelerometer, and pitch, roll, and yaw from the gyroscope. This is because I could compute the low-pass filtered values and complementary values on the Python server. This design choice was made to allow me to push through more data as quickly as possible.\nData storage\nI used separate float arrays for time (which is an int), raw accel roll/pitch, and gyro roll/pitch/yaw. With 4 bytes per float (6 values) + delimiting characters (5), that is 44 bytes per sample. In particular, compared to alternative options, representing a float or int as a string takes up more space if the number is more than 4 digits. This is true for all of our data; therefore, I believe I am using the most efficient way to store these values.\nLab 2 global variables use 131,832 bytes. The Artemis has 384 kB RAM, leaving roughly 252 kB for dynamic allocation. At 44 bytes per sample, this allows storing about 5700 samples. At a ~330 Hz (see below for the calculation) sample rate, that corresponds to roughly 17 seconds of continuous IMU data.\n5 seconds of IMU data\nI collected at least 5 seconds of IMU data and sent it over Bluetooth to verify the pipeline.\nThis section demonstrates that I can send 5 seconds of IMU data, showing the stored IMU data array with timestamps and start/end flags.\nHere is the beginning and end of the csv for the data I collected for about 5.1 seconds.\nBeginning of the IMU data collected for 5+ seconds\nEnd of the IMU data collected for 5+ seconds\nThere is a total of 1663 samples collected in 5 seconds, which gives about 1663 / 5 = 332.6 Hz for data transfer.\nRC Stunts\nBelow are videos of the RC car stunts powered by battery.\nRC car stunt 1\nRC car stunt 2\nFrom playing with the car, I noticed that the RC car is quick at reacting to any signal sent from the controller. I observed the car's turning, driving straight, and drifting. It has a great self-turning mechanism if you hold down the turning trigger. I also noticed that it seems to maintain a constant speed while turning, and how easily it can be flipped over.\nBonus: I was able to get the RC car on its side and drive it with only 2 wheels on the ground. Not really useful, but I thought it was interesting.\nCollaboration\nI collaborated with: Ananya Jajodia.\nI referenced: Lucca Correia's site for FFT debugging and Sampling data section.\nChatGPT was used for: code debugging + plot generation + website formatting."},{"url":"http://127.0.0.1:1111/Fast Robots Stuff/lab-1/","title":"Lab 1: Artemis and Bluetooth","body":"Lab 1A\nDuring section 1A, I installed the Arduino IDE and the corresponding libraries and board manager following a given tutorial and hooked up a physical connection from my computer to communicate with the SparkFun RedBoard Artemis Nano. After selecting the correct Board (RedBoard Artemis Nano) and Port, I verified programming and serial communication by running the required example sketches:\nBasics_blink\nApollo3_serial\nApollo3_analogRead\nPDM_microphoneOutput\nBlink\nThe Artemis board flashed its onboard LED as expected.\nBlink test video\nSerial\nThe Artemis received a string over USB serial and echoed it back as I typed into the Serial Monitor, confirming serial RX/TX.\nSerial communication test\nAnalogRead with Temperature Sensor\nThe onboard temperature sensor responded to heat (touch/breath), showing changing readings over time. In this case, I was blowing hot air to increase the temperature.\nTemperature sensor test\nMicrophone Output\nThe PDM microphone output changed with voice/whistle input, confirming the microphone pipeline works. In this case, I was whistling in the background to increase the sound frequency.\nMicrophone output test\nPart A of this lab is mainly to set up and test if the microcontroller functions properly with the computer, which it does.\nLab 1B\nIntroduction\nWith regards to the prelab and background reading, this is what I understand:\nBluetooth Low Energy (BLE) enables a lightweight communication link between my computer and the Artemis board. At a high level:\nThe Artemis acts as a BLE peripheral that advertises a service (UUID).\nThe computer acts as the BLE central, connects to the advertised service, and interacts with characteristics.\nCharacteristics support operations like Read, Write, and Notify. In this lab, I used Write to send commands to the Artemis and Notify to stream messages back to the laptop.\nThe code provided to me supports, including but not limited to, the following functionality:\nble_arduino.ino: Arduino sketch running on the Artemis (defines service + RX/TX characteristics and command handling).\nRobotCommand.h: parses incoming command strings of the form &lt;cmd_type&gt;:&lt;value1&gt;|&lt;value2&gt;|...\nEString.h: safely constructs outgoing strings (including float formatting) without relying on printf float support.\ndemo.ipynb: Python/Jupyter notebook used to connect, send commands, and receive notifications.\nUseful functions:\nble.connect() / ble.disconnect()\nble.send_command(cmd_type, data)\nble.start_notify(uuid, handler)\nble.bytearray_to_string(byteArray)\nSetup\nInstalled virtual environment tooling: python3 -m pip install --user virtualenv\nCreated venv: python3 -m venv FastRobots_ble\nActivated: source FastRobots_ble/bin/activate\nInstalled packages: pip install numpy pyyaml colorama nest_asyncio bleak jupyterlab\nStarted JupyterLab: jupyter lab\nAfter running uuid4(), I updated connections.yaml with my Artemis MAC address (from the Serial Monitor) and a unique BLE service UUID.\nArtemis MAC address output\nUpdated connections.yaml (service UUID + MAC)\nConnected successfully to the Artemis Nano board in Python:\nSuccessful BLE connection\nTASK 1\nI sent a string from my computer using ECHO. The Artemis constructed an augmented reply and transmitted it back over the TX string characteristic.\nArtemis:\nPython:\nECHO output received on laptop\nTASK 2\nI sent three floats with SEND_THREE_FLOATS and extracted them on the Artemis.\nArtemis:\nPython:\nSEND_THREE_FLOATS serial output\nTASK 3\nI added GET_TIME_MILLIS, which replies with a timestamp string formatted as T:&lt;millis&gt;. The results of this task are shown in Task 4. I also had to add GET_TIME_MILLIS to cmd_types.py in the right order within the types file.\nArtemis:\nTASK 4\nI set up a minimal notification handler in Python to receive strings from the Artemis via BLE notifications.\nPython:\nNotification handler receiving Artemis strings\nTASK 5\nI ran a short for loop sending 50 GET_TIME_MILLIS repeatedly and used the timestamps received to estimate throughput. I wrote the for loop in the Jupyter notebook; equivalently, it is talking to the Artemis board 50 times via BLE.\nPython:\nFrom the printed timestamps, the average inter-message gap was approximately 58.66 ms, corresponding to 17.05 messages/sec. Each message being 9 characters long means its payload is about 9 bytes (1 byte per character), giving an effective payload throughput of approximately:\ndata rate ≈ (messages/sec) × (bytes/message) = 153.43 bytes/sec\nGET_TIME_MILLIS loop output\nTASK 6\nI implemented an Arduino timestamp buffer (global array) of size 500 (arbitrary) and added SEND_TIME_DATA to send stored timestamps back to the laptop. You can request it for any integer number of times. It first stores the timestamps in the buffer by running millis() the requested number of times. Then it publishes the buffer results one by one to my computer. I added additional logic for handling the buffer overflow, which sends all the data once the buffer is full, then clears it and restarts the timestamp collection. This method balances the reliability of the data and the availability of data. Again, I had to add SEND_TIME_DATA to cmd_types.py in the right order within the types file.\nAdvantage: Sampling happens locally without waiting for BLE round-trips.\nImplementation: Store up to capacity, then transmit and restart.\nArtemis:\nSEND_TIME_DATA output\nTASK 7\nI added a second buffer array for temperature values (same length as timestamps = 500). Both are global arrays. Each index corresponds to a paired measurement. GET_TEMP_READINGS sends T:&lt;ms&gt; , TEMP:&lt;val&gt; on each line. It allows the users to request the number of times they want to get the data, and it fetches the current time and temp sequentially, ensuring their values are synchronized. The publishing and buffer overflow logic is handled just like TASK 6. Again, I had to add GET_TEMP_READINGS to cmd_types.py in the right order within the types file.\nArtemis:\nTimestamp + temperature streaming\nTASK 8\nMethod 1 (Task 5) fetches and sends the data one at a time. It is definitely slower for recording because each sample depends on BLE command/response timing, wasting a lot of time sending and receiving communication. It is, however, useful for simple debugging and low-rate telemetry when real-time interaction matters. Especially, if we decided to have a really large buffer, the data might be stale by the time you get it on the computer side.\nMethod 2 (Tasks 6–7) fetches in volume and sends one at a time. It records data faster because the sampling is local; BLE is only used afterward to transmit stored results. This is ideal for burst logging and experiments where high-rate sampling matters more than immediate real-time feedback. The downside is the delayed availability of the data on the laptop, as I mentioned, and transmission can still be limited by notification throughput.\nHow quickly can Method 2 record data?\nIt is primarily limited by the sensor read and loop overhead on the Artemis. In my test sending 400 requests for SEND_TIME_DATA, recording 400 samples took approximately 13 ms, or roughly 0.03 ms/sample, which is almost 2000 times faster.\nMemory estimate (384 kB RAM):\nEach timestamp is 4 bytes (int), and each temp is 4 bytes (float) → 8 bytes per paired sample. Including the global variables I have, which take up 34,152 bytes, but ignoring other overhead, the theoretical upper bound is approximately:\n349,848 bytes / 8 ≈ 43,731 sample pairs could potentially be stored in the array before the board runs out of dynamic memory.\nA more realistic, safe capacity is lower, depending on current global/static memory usage reported by the Arduino IDE.\nDiscussion and Conclusion\nI learned how BLE services/characteristics map to read/write/notify behavior and how the Artemis acts as a peripheral device. I also learned to write commands to control the Artemis board using lower-level libraries like RobotCommand.h. Finally, I learned about the limits on how fast the Artemis's temperature sensor can be polled, which is really fast.\nI implemented an interesting way of handling the buffer overflow for TASKS 6-7, balancing between the availability of data and the reliability of data.\nThe main debugging challenge was making sure that the environment was set up to run the Jupyter notebook. I spent way too long on it when it was just an easy fix. But now I really remember it. Also, I thought about perhaps sending the buffer information in one message, which would depend on how long I could make an EString. Theoretically, I can make it 255 bytes with the Arduino BLE limit, which for TASKS 5-6, is 20-30 messages depending on the length of the timestamp. Realistically, it would not impact the reliability of the data, because the data is already recorded in the buffer, but it can decrease the delay in the delivery of the data.\nCollaboration\nI collaborated with: Ananya Jajodia.\nI referenced: Lucca Correia's site for web design and lab writeup.\nChatGPT was used for: code debugging + website formatting."}]